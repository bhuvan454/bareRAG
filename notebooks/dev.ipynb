{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# add backends to path\n",
    "# sys.path.append('C:/Users/bkcmk5/Desktop/Projects_for_portfolio/ollm-apps/backend/apps/rag/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"./CHROMA/\"\n",
    "DATA_PATH = \"../backedn/apps/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(documents_dir):\n",
    "    print(f\"Loading documents from \")\n",
    "\n",
    "    document_loader = PyPDFDirectoryLoader(documents_dir)\n",
    "    documents = document_loader.load()\n",
    "    # logging.info(f\"\\nLoaded {len(documents)} documents\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from \n",
      "page_content=\"Bhuvan\\nChennoju\\n+1\\n816-377-7628\\n/\\nbhuvanchennojuwork@gmail.com\\n/\\nLinkedin\\n/\\nPortfolio\\n/\\nKansas\\nCity,\\nMO,\\nUSA\\nSummary\\nData\\nscientist\\nwith\\n4+\\nyears\\nof\\nexperience\\nin\\nmachine\\nlearning,\\ndeep\\nlearning,\\ndata\\nengineering,\\nand\\nanalytics\\nwith\\nexpertise\\nin\\ncloud\\ntechnologies.\\nProven\\ntrack\\nrecord\\nof\\nsuccessful\\nprojects\\nin\\nML\\ndevelopment,\\npublications\\nin\\npeer-reviewed\\njournals,\\nand\\neffective\\ncommunication\\nwith\\nstakeholders\\nat\\nall\\nlevels.\\nWork\\nExperience\\nData\\nScientist\\n|\\nStowers\\nInstitute\\nfor\\nMedical\\nResearch\\nAugust\\n2023\\n-\\nPresent\\n●\\nDeveloped\\npredictive\\nmodels\\nwith\\nconvolutional\\nneural\\nnetwork\\narchitecture\\nto\\npredict\\nbinding\\nsites\\nin\\nDNA-protein\\ninteractions\\nusing\\nKeras\\nand\\nTensorFlow,\\nimproving\\nprediction\\naccuracy\\nby\\n15%\\nin\\nmulti-task\\nregression.\\n●\\nArchitected\\nML\\noptimization\\ntechniques,\\nincluding\\ndilated\\nconvolutions,\\nregularization,\\nand\\ncross-fold\\nvalidation,\\nimproved\\nthe\\nmodel\\ngeneralization\\non\\ntest\\ndata\\nperformance\\nby\\n10%.\\n●\\nEngineered\\na\\nPython-based\\nETL\\nstatistical\\npipeline\\nfor\\nprocessing\\ngenomic\\ntext\\ndata\\nat\\n1.5\\nGB\\nper\\nsecond\\nto\\nextract\\nthe\\ncontextual\\nsequences\\ncontinuous\\nbiosignals\\nfrom\\nraw\\ndata\\nfiles.\\n●\\nExperienced\\nin\\nanalyzing\\nanalytical\\ndrivers\\nfrom\\nstructured\\nand\\nunstructured\\ndatasets\\nusing\\nPython(NumPy,\\nSciPy,\\nMatplotlib,\\nPandas,\\nSQL,\\nR,\\nggplot)\\nand\\nGPU\\nclusters\\nfor\\nscalability.\\nData\\nScience\\nConsultant\\n|\\nUniversity\\nof\\nMissouri-Kansas\\nCity\\nSeptember\\n2023\\n–\\nFebruary\\n2024\\n●\\nConducted\\n10+\\ninterviews\\nand\\nrequirements-gathering\\nsessions\\nwith\\nnon-technical\\nusers\\nto\\nformulate\\nthe\\ndata\\nworkflow\\nand\\ndata\\nrequirements\\nto\\ndevelop\\nautomated\\nanalytics\\ndashboards\\nfor\\nthe\\nfinancial\\nhealth\\nof\\ngrant-funded\\nprojects.\\n●\\nDesigned\\nand\\nimplemented\\nend-to-end\\nAzure\\ndata\\npipelines\\nto\\nETL\\noperations,\\nresulting\\nin\\na\\n20%\\nreduction\\nin\\ndata\\nprocessing\\ntime\\nand\\na\\n15%\\nincrease\\nin\\noverall\\nstorage\\nefficiency.\\n●\\nWith\\nAzure\\nFunctions,\\nAzure\\nDatabricks,\\nand\\nAzure\\nSynapse\\nAnalytics,\\nremoved\\nthe\\nbottlenecks\\nin\\ndata\\nprocessing\\nworkflows\\nand\\nreduced\\n10\\nman-hours\\nin\\nbiweekly\\ndata\\nreporting.\\n●\\nUtilized\\nDAX\\nand\\nM\\nlanguage\\nin\\nPower\\nBI\\nto\\ncreate\\ndynamic\\ndashboards,\\nintegrating\\n7\\ndivisions'\\nfinancial\\ndata\\nto\\nbring\\ntangible\\nKPIs\\nacross\\nthe\\nengineering\\nschool.\\n●\\nProduced\\n5\\nthrough\\ntechnical\\ndocumentation\\nand\\nconducted\\n3+\\nhours\\nof\\nhands-on\\ntraining\\nsessions\\nfor\\nend-users.\\nData\\nScientist\\n|\\nComputational\\nIntelligence\\n&\\nBI\\nLaboratory\\nOctober\\n2021\\n-\\nJuly\\n2023\\n●\\nLed\\nend-to-end\\ndevelopment\\nof\\nML-based\\nperson\\nidentification\\nand\\nauthentication\\nframework,\\nemploying\\nAgile\\nmethodologies\\nfor\\nstreamlined\\ndelivery\\nof\\ndeployable\\nsoftware.\\n●\\nCleaned\\nand\\nanalyzed\\ncomplex\\nbiometric\\ndatasets,\\nidentifying\\nkey\\nrelationships\\nand\\ncorrelations\\nbetween\\nvariables.\\n●\\nDeveloped\\nResNet-based\\nHuman\\nAuthentication\\nframework\\nwith\\nAUC\\nexceeding\\n85%\\nand\\naccuracy\\nof\\n80%.\\n●\\nDesigned\\nfNIRS-specific\\nHuman\\nIdentification\\nframework\\nwith\\nAzure\\nAutoML,\\nachieving\\nan\\naccuracy\\nsurpassing\\n87%.\\n●\\nSuccessfully\\nsubmitted\\nand\\npublished\\npeer-reviewed\\nresearch\\npapers\\non\\nmachine\\nlearning\\nand\\ndeep\\nlearning.\\nData\\nScientist\\nIntern\\n|\\nT-Mobile\\nUSA\\nInc\\nMay\\n2022\\n–\\nAugust\\n2022\\n●\\nBuilt\\nand\\ndeployed\\nproof\\nof\\nconcept\\nimage\\nclassifiers\\nto\\ncompare\\n5G\\nedge\\ncomputing\\nwith\\ntraditional\\ncloud,\\nachieving\\na\\nnotable\\n13%\\nreduction\\nin\\ninference\\ntime\\nwith\\nedge\\ncomputing.\\n●\\nUtilized\\nadvanced\\ndeep\\nlearning\\ntechniques,\\nincluding\\ndilated\\nconnections,\\naugmentations,\\nand\\noptimization,\\nto\\nenhance\\ntraining\\nperformance\\nby\\n18%\\naccuracy\\nfor\\ngesture\\nrecognition\\nmodels\\nfor\\nVR\\ninput\\ndevices.\\n●\\nCreated\\ninteractive\\ndata\\nvisualizations\\nusing\\nPlotly,\\nto\\ndeliver\\nengaging\\nand\\ninformative\\nvisuals.\\n●\\nPresented\\ndata-driven\\noutcomes\\nto\\nleadership,\\nresulting\\nin\\n25%\\nsavings\\nin\\nthe\\nquarterly\\nbudget\\nfor\\nEdge\\ncompute\\nR&D.\\nPublications\\n●\\nAnalysis\\nof\\nfNIRS\\nas\\na\\nBiometric\\nModality,\\nBhuvan\\net\\nal.,\\nIEEE\\nIJBC\\n2023. \\n-\\nDemonstrated\\nthe\\nability\\nof\\nfNIRS\\nsignals\\nas\\nbiometrics\\nwith\\nmachine\\nlearning\\ntechniques.\\n●\\nA\\nWrist-worn\\nDiffuse\\nOptical\\nTomography\\nBiometric\\nSystem\\n,\\nSssrk\\net\\nal.,\\nBIOSEG\\n2023. \\n-\\nBuilt\\ndeployable\\ndeep-learning\\nmodels\\nto\\nidentify\\nand\\nauthenticate\\na\\nperson\\nbased\\non\\nwrist\\nvein\\npatterns\\nfor\\na \\nwearable\\nstandalone\\nDOT\\ndevice.\\nEducation\\nMS\\nin\\nComputer\\nScience\\n(\\nThesis\\n)\\n-\\nUniversity\\nof\\nMissouri\\n-\\nKansas\\nCity,\\nUSA\\nBachelor\\nof\\nTechnology\\n-\\nNational\\nInstitute\\nof\\nTechnology,\\nIndia\\nCertifications\\n●\\nMicrosoft\\nCertified\\nAzure\\nData\\nScientist\\nAssociate\\n-\\nDP\\n-\\n100\\nExam \\n●\\nMicrosoft\\nCertified\\nAzure\\nData\\nEngineer\\nAssociate\\n-\\nDP\\n-\\n203\\nExam\\nSkills\\nSummary\\nPython\\nR\\nSQL\\nNumPy\\nPandas\\nSciPy\\nScikit-learn\\nMatplotlib\\nPlotly\\nPyTorch\\nTensorFlow\\nDash\\nD3.js\\n●  \\n●\\n●\\n● \\n● \\n● \\n●\\n●\\n● \\n● \\n● \\n● \\nTableau\\nPower\\nBI\\nAzure\\nPostgreSQL\\nGit\\nExcel\\nMS\\nSQL\\nserver\\nFlask\\nNoSQL\\nHTML\\n●\\n●\\n● \\n●\\n●\\n●\\n●\\n●\\n● \\n● \\n\" metadata={'source': 'myresume.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents('./')\n",
    "for doc in documents:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size= 800,\n",
    "        chunk_overlap= 80,\n",
    "        length_function= len,\n",
    "        is_separator_regex = False,\n",
    "    )\n",
    "    return splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
